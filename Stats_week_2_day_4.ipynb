{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "096a26fb",
   "metadata": {
    "id": "GK0NW_2EjULQ"
   },
   "source": [
    "<table align=\"left\" width=100%>\n",
    "    <tr>\n",
    "        <td width=\"20%\">\n",
    "            <img src=\"GL-2.png\">\n",
    "        </td>\n",
    "        <td>\n",
    "            <div align=\"center\">\n",
    "                <font color=\"#21618C\" size=8px>\n",
    "                  <b> Faculty Notebook <br> ( Day 3) </b>\n",
    "                </font>\n",
    "            </div>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a66606fa",
   "metadata": {
    "id": "zvAE5vE3jULR"
   },
   "source": [
    "## Table of Content\n",
    "\n",
    "1. **[Import Libraries](#lib)**\n",
    "2. **[One-way & Two Way ANOVA](#1way)**\n",
    "    - 2.1 - **[Post-hoc Analysis](#post-hoc)**\n",
    "    - 2.2 - **[Non Parametric Test (Additional Content)](#non-para)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f330ad",
   "metadata": {
    "id": "PfsUFjVbjULS"
   },
   "source": [
    "<a id=\"lib\"></a>\n",
    "# 1. Import Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42a4706",
   "metadata": {
    "id": "soadpiTzjULT"
   },
   "source": [
    "**Let us import the required libraries.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79574235",
   "metadata": {
    "id": "6FixCmEsjULU"
   },
   "outputs": [],
   "source": [
    "# import 'pandas' \n",
    "import pandas as pd \n",
    "\n",
    "# import 'numpy' \n",
    "import numpy as np\n",
    "\n",
    "# import subpackage of matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import 'seaborn'\n",
    "import seaborn as sns\n",
    "\n",
    "# to suppress warnings \n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')\n",
    "\n",
    "# import 'stats' package from scipy library\n",
    "from scipy import stats\n",
    "\n",
    "# import statistics to perform statistical computations\n",
    "import statistics\n",
    "\n",
    "# to test the normality \n",
    "from scipy.stats import shapiro\n",
    "\n",
    "# import statsmodels\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "\n",
    "# import the functions to perform Chi-square tests\n",
    "from scipy.stats import chi2_contingency\n",
    "from scipy.stats import chi2\n",
    "from scipy.stats import chisquare\n",
    "\n",
    "# function to perform post-hoc test\n",
    "import statsmodels.stats.multicomp as mc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b5387d7",
   "metadata": {
    "id": "0xOunnbOjULY"
   },
   "outputs": [],
   "source": [
    "# set the plot size using 'rcParams'\n",
    "# once the plot size is set using 'rcParams', it sets the size of all the forthcoming plots in the file\n",
    "# pass width and height in inches to 'figure.figsize' \n",
    "plt.rcParams['figure.figsize'] = [15,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4315f85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.143252849784718"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# F Critical...\n",
    "\n",
    "stats.f.ppf(0.95, dfn = 2, dfd = 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4a2267",
   "metadata": {},
   "source": [
    "<a id=\"1way\"></a>\n",
    "# 2. One-way ANOVA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4483562e",
   "metadata": {},
   "source": [
    "It is used to check the equality of population means for more than two independent samples. Each group is considered as a `treatment`. It assumes that the samples are taken from normally distributed populations. To check this assumption we can use the `Shapiro-Wilk Test.` Also, the population variances should be equal; this can be tested using the `Levene's Test`.\n",
    "\n",
    "The null and alternative hypothesis is given as:\n",
    "<p style='text-indent:20em'> <strong> $H_{0}$: The averages of all treatments are the same. </strong></p>\n",
    "<p style='text-indent:20em'> <strong> $H_{1}$: At least one treatment has a different average. </strong></p>\n",
    "\n",
    "Consider there are `t` treatments and `N` number of total observations. The test statistic is given as:\n",
    "<p style='text-indent:28em'> <strong> $F = \\frac{MTrSS}{MESS} $</strong></p>\n",
    "\n",
    "Where,<br>\n",
    "MTrSS = $\\frac{TrSS}{df_{Tr}}$<br>\n",
    "\n",
    "TrSS = $\\sum_{i}^{t}\\sum_{j}^{n_{i}}n_{i}(\\bar{x_{i}}. - \\bar{x}..)$<br> $n_{i}$ is the number of observations in $i^{th}$ treatment. <br>$\\bar{x_{i}}.$ is the mean over $i^{th}$ treatment <br> $\\bar{x}..$ is the grand mean (i.e. mean of all the observations). <br>\n",
    "\n",
    "$df_{Tr}$ is the degrees of freedom for treatments (= $t-1$)\n",
    "\n",
    "MESS = $\\frac{ESS}{df_{e}}$<br>\n",
    "\n",
    "ESS = $\\sum_{i}^{t}\\sum_{j}^{n_{i}}{(x_{ij} - \\bar{x_{i}}.)}^{2}$\n",
    "\n",
    "$df_{e}$ is the degrees of freedom for error (= $N-t$)\n",
    "\n",
    "Under $H_{0}$, the test statistic follows F-distribution with ($t-1,  N-t$) degrees of freedom.\n",
    "\n",
    "\n",
    "### Difference between One Way anova and Two Way Anova\n",
    "\n",
    "* One Way Anova is when you introduce One Categorical Variable & A Numerical Variable.\n",
    "* On the other hand, if we want to analyse multiple categorical variables with a numerical variable, then it is called Two Way Anova.\n",
    "\n",
    "* For example Pclass vs Fare is an example of One Way Anova with One categorical variable with 03 Levels (Class1, Class2 & 3) and a Numerical Variable.\n",
    "\n",
    "* Whereas the Two Way Anova is two or more categorical variables with a numerical variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37bada97",
   "metadata": {},
   "source": [
    "Let us calculate the F values for different levels of significance ($\\alpha$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6273ed5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alpha</th>\n",
       "      <th>F</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.25</td>\n",
       "      <td>1.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.10</td>\n",
       "      <td>2.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.05</td>\n",
       "      <td>2.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.01</td>\n",
       "      <td>4.85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   alpha     F\n",
       "0   0.25  1.55\n",
       "1   0.10  2.32\n",
       "2   0.05  2.98\n",
       "3   0.01  4.85"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let us find the F-values for different alpha values with (10,10) degrees of freedom\n",
    "\n",
    "# create an empty dataframe to store the alpha and corresponding F-value\n",
    "df_F = pd.DataFrame()\n",
    "\n",
    "# create a dictionary of different alpha values\n",
    "alpha =  [0.25, 0.1, 0.05, 0.01] \n",
    "\n",
    "# use for loop to calculate the F-value for each alpha value\n",
    "for i in range(len(alpha)):\n",
    "    \n",
    "    # use 'stats.f.isf()' to find the F-value corresponding to the upper tail probability 'q'\n",
    "    # pass the value of 'alpha' to the parameter 'q'\n",
    "    # pass the (10,10) degrees of freedom to the parameter 'dfn' and 'dfd' respectively\n",
    "    # use 'round()' to round-off the value to 2 digits\n",
    "    f_val = np.abs(round(stats.f.isf(q = alpha[i], dfn = 10, dfd = 10), 2))\n",
    "\n",
    "    # create a dataframe using dictionary to store the alpha and corresponding F-value\n",
    "    # set the loop iterator 'i' as the index of the dataframe\n",
    "    row =  pd.DataFrame({\"alpha\": alpha[i], \"F\": f_val}, index = [i])\n",
    "\n",
    "    # append the row to the dataframe 'df_F'\n",
    "    df_F = df_F.append(row)\n",
    "\n",
    "# print the final dataframe\n",
    "df_F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587f1cd5",
   "metadata": {},
   "source": [
    "### Lets Solve for Anova. Here is a Sample Dataset with 3 Categories. Lets apply Anova step by step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a07e654",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat1 = [1,2,5]\n",
    "cat2 = [2,4,2]\n",
    "cat3 = [2,3,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "224895c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.143252849784718"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# F Critical\n",
    "stats.f.isf(0.05, dfn = 2, dfd = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d97e1ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "F_onewayResult(statistic=0.049999999999999996, pvalue=0.9516215013591449)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# F Test\n",
    "stats.f_oneway(cat1, cat2, cat3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9322dcf5",
   "metadata": {},
   "source": [
    "### Example:\n",
    "\n",
    "#### 1. Total marks in aptitude exam are recorded for students with different race/ethnicity. Test whether all the races/ethnicities have an equal average score with 0.05 level of significance. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801660ff",
   "metadata": {},
   "source": [
    "Use the performance dataset of students available in the CSV file `students_data.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8c399cbc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>race/ethnicity</th>\n",
       "      <th>lunch</th>\n",
       "      <th>test preparation course</th>\n",
       "      <th>math score</th>\n",
       "      <th>reading score</th>\n",
       "      <th>writing score</th>\n",
       "      <th>total score</th>\n",
       "      <th>training institute</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>female</td>\n",
       "      <td>group B</td>\n",
       "      <td>standard</td>\n",
       "      <td>none</td>\n",
       "      <td>89</td>\n",
       "      <td>55</td>\n",
       "      <td>56</td>\n",
       "      <td>200</td>\n",
       "      <td>Nature Learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>female</td>\n",
       "      <td>group C</td>\n",
       "      <td>standard</td>\n",
       "      <td>completed</td>\n",
       "      <td>55</td>\n",
       "      <td>63</td>\n",
       "      <td>72</td>\n",
       "      <td>190</td>\n",
       "      <td>Nature Learning</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender race/ethnicity     lunch test preparation course  math score  \\\n",
       "0  female        group B  standard                    none          89   \n",
       "1  female        group C  standard               completed          55   \n",
       "\n",
       "   reading score  writing score  total score training institute  \n",
       "0             55             56          200    Nature Learning  \n",
       "1             63             72          190    Nature Learning  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the students performance data \n",
    "df_student = pd.read_csv('StudentsPerformance (2).csv')\n",
    "\n",
    "# display the first two observations\n",
    "df_student.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087fc792",
   "metadata": {},
   "source": [
    "The null and alternative hypothesis is:\n",
    "\n",
    "H<sub>0</sub>: The average score of all races/ethnicities is same<br>\n",
    "H<sub>1</sub>: At least one race/ethnicity has a different average score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "08747b71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['group B', 'group C', 'group A', 'group D', 'group E'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the Levels in Race\n",
    "df_student[\"race/ethnicity\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "522a05c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as sfa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49e0fb2",
   "metadata": {},
   "source": [
    "There are total 5 unique race/ethnicity in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "895477ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical Library\n",
    "df_student[\"total_score\"] = df_student[\"total score\"]\n",
    "df_student[\"race\"] = df_student[\"race/ethnicity\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8d5101d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression\n",
    "model = sfa.ols(\"total_score~race\", data = df_student).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8d37e97e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>total_score</td>   <th>  R-squared:         </th> <td>   0.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>  -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>  0.7891</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 27 Oct 2023</td> <th>  Prob (F-statistic):</th>  <td> 0.532</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>12:22:35</td>     <th>  Log-Likelihood:    </th> <td> -4560.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1000</td>      <th>  AIC:               </th> <td>   9132.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   995</td>      <th>  BIC:               </th> <td>   9156.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     4</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "         <td></td>            <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>       <td>  201.1000</td> <td>    2.446</td> <td>   82.215</td> <td> 0.000</td> <td>  196.300</td> <td>  205.900</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>race[T.group B]</th> <td>    2.8789</td> <td>    2.969</td> <td>    0.970</td> <td> 0.333</td> <td>   -2.948</td> <td>    8.706</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>race[T.group C]</th> <td>   -0.8712</td> <td>    2.770</td> <td>   -0.315</td> <td> 0.753</td> <td>   -6.306</td> <td>    4.564</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>race[T.group D]</th> <td>    0.5360</td> <td>    2.837</td> <td>    0.189</td> <td> 0.850</td> <td>   -5.030</td> <td>    6.102</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>race[T.group E]</th> <td>    0.6143</td> <td>    3.135</td> <td>    0.196</td> <td> 0.845</td> <td>   -5.538</td> <td>    6.767</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 0.480</td> <th>  Durbin-Watson:     </th> <td>   1.990</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.787</td> <th>  Jarque-Bera (JB):  </th> <td>   0.568</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.030</td> <th>  Prob(JB):          </th> <td>   0.753</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.900</td> <th>  Cond. No.          </th> <td>    8.57</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &   total\\_score   & \\textbf{  R-squared:         } &     0.003   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &    -0.001   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &    0.7891   \\\\\n",
       "\\textbf{Date:}             & Fri, 27 Oct 2023 & \\textbf{  Prob (F-statistic):} &    0.532    \\\\\n",
       "\\textbf{Time:}             &     12:22:35     & \\textbf{  Log-Likelihood:    } &   -4560.8   \\\\\n",
       "\\textbf{No. Observations:} &        1000      & \\textbf{  AIC:               } &     9132.   \\\\\n",
       "\\textbf{Df Residuals:}     &         995      & \\textbf{  BIC:               } &     9156.   \\\\\n",
       "\\textbf{Df Model:}         &           4      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                         & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept}       &     201.1000  &        2.446     &    82.215  &         0.000        &      196.300    &      205.900     \\\\\n",
       "\\textbf{race[T.group B]} &       2.8789  &        2.969     &     0.970  &         0.333        &       -2.948    &        8.706     \\\\\n",
       "\\textbf{race[T.group C]} &      -0.8712  &        2.770     &    -0.315  &         0.753        &       -6.306    &        4.564     \\\\\n",
       "\\textbf{race[T.group D]} &       0.5360  &        2.837     &     0.189  &         0.850        &       -5.030    &        6.102     \\\\\n",
       "\\textbf{race[T.group E]} &       0.6143  &        3.135     &     0.196  &         0.845        &       -5.538    &        6.767     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       &  0.480 & \\textbf{  Durbin-Watson:     } &    1.990  \\\\\n",
       "\\textbf{Prob(Omnibus):} &  0.787 & \\textbf{  Jarque-Bera (JB):  } &    0.568  \\\\\n",
       "\\textbf{Skew:}          & -0.030 & \\textbf{  Prob(JB):          } &    0.753  \\\\\n",
       "\\textbf{Kurtosis:}      &  2.900 & \\textbf{  Cond. No.          } &     8.57  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:            total_score   R-squared:                       0.003\n",
       "Model:                            OLS   Adj. R-squared:                 -0.001\n",
       "Method:                 Least Squares   F-statistic:                    0.7891\n",
       "Date:                Fri, 27 Oct 2023   Prob (F-statistic):              0.532\n",
       "Time:                        12:22:35   Log-Likelihood:                -4560.8\n",
       "No. Observations:                1000   AIC:                             9132.\n",
       "Df Residuals:                     995   BIC:                             9156.\n",
       "Df Model:                           4                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "===================================================================================\n",
       "                      coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-----------------------------------------------------------------------------------\n",
       "Intercept         201.1000      2.446     82.215      0.000     196.300     205.900\n",
       "race[T.group B]     2.8789      2.969      0.970      0.333      -2.948       8.706\n",
       "race[T.group C]    -0.8712      2.770     -0.315      0.753      -6.306       4.564\n",
       "race[T.group D]     0.5360      2.837      0.189      0.850      -5.030       6.102\n",
       "race[T.group E]     0.6143      3.135      0.196      0.845      -5.538       6.767\n",
       "==============================================================================\n",
       "Omnibus:                        0.480   Durbin-Watson:                   1.990\n",
       "Prob(Omnibus):                  0.787   Jarque-Bera (JB):                0.568\n",
       "Skew:                          -0.030   Prob(JB):                        0.753\n",
       "Kurtosis:                       2.900   Cond. No.                         8.57\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Regression Output\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "351176ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>df</th>\n",
       "      <th>sum_sq</th>\n",
       "      <th>mean_sq</th>\n",
       "      <th>F</th>\n",
       "      <th>PR(&gt;F)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>race</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1699.671655</td>\n",
       "      <td>424.917914</td>\n",
       "      <td>0.78911</td>\n",
       "      <td>0.532294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Residual</th>\n",
       "      <td>995.0</td>\n",
       "      <td>535785.303345</td>\n",
       "      <td>538.477692</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             df         sum_sq     mean_sq        F    PR(>F)\n",
       "race        4.0    1699.671655  424.917914  0.78911  0.532294\n",
       "Residual  995.0  535785.303345  538.477692      NaN       NaN"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Anova table...\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "anova_lm(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9977294f",
   "metadata": {},
   "source": [
    "Since the Pvalue is greater than Alpha, We Fail to Reject the Ho meaning that the Avg Marks are same across all the categories.\n",
    "\n",
    "In other words, the Race/Ethinicity has nothing to do with the scores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d85c0eb",
   "metadata": {},
   "source": [
    "#### Perform ANOVA to test the equality of means."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f80bea",
   "metadata": {},
   "source": [
    "Let us check the normality of the total marks of students from all the groups."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe506c95",
   "metadata": {},
   "source": [
    "From the above result, we can see that the p-value is greater than 0.05, thus we can say that the total marks of students from each group are normally distributed. Thus the assumption of normality is satisfied."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ec9350",
   "metadata": {},
   "source": [
    "Let us check the equality of variances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efc35af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform Levene's test for the equality of variances \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0cf577",
   "metadata": {},
   "source": [
    "From the above result, we can see that the p-value is greater than 0.05, thus we can say that the population variances are equal for all the samples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226a533f",
   "metadata": {},
   "source": [
    "For ⍺ = 0.05 and degrees of freedom (= t-1, N-t) = (4, 995), calculate the critical value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e52e97e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the F-value for 95% of confidence level\n",
    "# use 'stats.f.isf()' to find the F-value corresponding to the upper tail probability 'q'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8fd03a",
   "metadata": {},
   "source": [
    "i.e. if the test statistic value is greater than 2.3809 then we reject the null hypothesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d3bf844",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform one-way ANOVA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e40fc25",
   "metadata": {},
   "source": [
    "We can also use the `anova_lm()` in statsmodels library to perform ANOVA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff7d57f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform one-way ANOVA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4ef9d5",
   "metadata": {},
   "source": [
    "#### 2. Ryan is a production manager at an industry manufacturing alloy steels. They have 4 machines - A, B, C and D. Ryan wants to study whether all the machines have equal efficiency. Ryan collects data of tensile strength from all the 4 machines as given. Test at 5% level of significance.\n",
    "\n",
    "<img src='1_ANOVA.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9395b897",
   "metadata": {},
   "source": [
    "The null and alternative hypothesis is:\n",
    "\n",
    "H<sub>0</sub>: The average tensile strength due to all the machines is the same<br>\n",
    "H<sub>1</sub>: The average tensile strength due to at least one machines is different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f0706488",
   "metadata": {},
   "outputs": [],
   "source": [
    "# given data\n",
    "# tensile strength due to machine A\n",
    "A = [68.7, 75.4, 70.9, 79.1, 78.2]\n",
    "\n",
    "# tensile strength due to machine B\n",
    "B = [62.7, 68.5, 63.1, 62.2, 60.3]\n",
    "\n",
    "# tensile strength due to machine C\n",
    "C = [55.9, 56.1, 57.3, 59.2, 50.1]\n",
    "\n",
    "# tensile strength due to machine D\n",
    "D = [80.7, 70.3, 80.9, 85.4, 82.3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec74b7c1",
   "metadata": {},
   "source": [
    "### One way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b5e3c5dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.238871517453585"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# F Critical\n",
    "stats.f.isf(0.05, dfn = 3, dfd = 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1fa02f37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "F_onewayResult(statistic=32.03072350199285, pvalue=5.375613532781072e-07)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# F Test\n",
    "stats.f_oneway(A, B, C, D)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b6bce6",
   "metadata": {},
   "source": [
    "#### Perform ANOVA to test the equality of means.\n",
    "\n",
    "Let us check the normality of the tensile strength of all the machines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "78cbdff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe using a dictionary from given data\n",
    "df_machine = pd.DataFrame({\"Machine\":[\"Machine_A\", \"Machine_B\", \"Machine_C\",\n",
    "                        \"Machine_D\"]*5, \n",
    "             \"Strength\":[68.7, 62.7, 55.9, 80.7, 75.4, 68.5,56.1,\n",
    "                         70.3,70.9,63.1,57.3,80.9,\n",
    "                         79.1,62.2,59.2,85.4,78.2,60.3,50.1,82.3]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9da53f13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Machine</th>\n",
       "      <th>Strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Machine_A</td>\n",
       "      <td>68.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Machine_B</td>\n",
       "      <td>62.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Machine_C</td>\n",
       "      <td>55.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Machine_D</td>\n",
       "      <td>80.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Machine_A</td>\n",
       "      <td>75.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Machine  Strength\n",
       "0  Machine_A      68.7\n",
       "1  Machine_B      62.7\n",
       "2  Machine_C      55.9\n",
       "3  Machine_D      80.7\n",
       "4  Machine_A      75.4"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_machine.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3f68af08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ShapiroResult(statistic=0.9503339529037476, pvalue=0.3721875548362732)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# perform Shapiro-Wilk test to test the normality\n",
    "# shapiro() returns a tuple having the values of test statistics and the corresponding p-value\n",
    "\n",
    "stats.shapiro(df_machine[\"Strength\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1fda1cf",
   "metadata": {},
   "source": [
    "From the above result, we can see that the p-value is greater than 0.05, thus we can say that the tensile strengths due to all the machines are normally distributed. Thus the assumption of normality is satisfied."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9784b6",
   "metadata": {},
   "source": [
    "Let us check the equality of variances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7e1ac34f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LeveneResult(statistic=0.3969333650936478, pvalue=0.7570021212992085)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# perform Levene's test for the equality of variances \n",
    "stats.levene(A, B, C, D)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b42dc10",
   "metadata": {},
   "source": [
    "From the above result, we can see that the p-value is greater than 0.05, thus we can say that the population variances are equal for all the samples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda1e461",
   "metadata": {},
   "source": [
    "Here t (=number of machines) = 4, N (=total observations) = 20 \n",
    "\n",
    "For ⍺ = 0.05, calculate the Critical Value...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c6a18650",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.238871517453585"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the F-value for 95% of confidence level\n",
    "# use 'stats.f.isf()' to find the F-value corresponding to the upper tail probability 'q'\n",
    "stats.f.isf(0.05, 3, 16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539972e8",
   "metadata": {},
   "source": [
    "i.e. if the test statistic value is greater than 3.2389 then we reject the null hypothesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ed0a543f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>df</th>\n",
       "      <th>sum_sq</th>\n",
       "      <th>mean_sq</th>\n",
       "      <th>F</th>\n",
       "      <th>PR(&gt;F)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Machine</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1778.0655</td>\n",
       "      <td>592.68850</td>\n",
       "      <td>32.030724</td>\n",
       "      <td>5.375614e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Residual</th>\n",
       "      <td>16.0</td>\n",
       "      <td>296.0600</td>\n",
       "      <td>18.50375</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            df     sum_sq    mean_sq          F        PR(>F)\n",
       "Machine    3.0  1778.0655  592.68850  32.030724  5.375614e-07\n",
       "Residual  16.0   296.0600   18.50375        NaN           NaN"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# perform one-way ANOVA\n",
    "model = sfa.ols(\"Strength~Machine\", data = df_machine).fit()\n",
    "\n",
    "anova_lm(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e314e54b",
   "metadata": {},
   "source": [
    "The above output shows that the test statistic is greater than 3.2389 and the p-value is less than 0.05. Thus we reject the null hypothesis and conclude that the average tensile strength for **at least one machine is different.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4f0bcb",
   "metadata": {},
   "source": [
    "<a id=\"post-hoc\"></a>\n",
    "## 2.1 Post-hoc Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c10a8de",
   "metadata": {},
   "source": [
    "If one-way ANOVA rejects the null hypothesis; we conclude that at least one treatment has a different mean. The test does not distinguish a treatment with the different average value. The post-hoc test or `multi comparison test` is used to identify such treatment(s).\n",
    "\n",
    "In this section, we study the `Tukey's HSD` test. The test calculates the mean difference for each pair of treatments and returns the pair(s) with different average. \n",
    "\n",
    "The test statistic of Tukey's HSD test is given as:\n",
    "<p style='text-indent:28em'> <strong> $T_{\\alpha} = q_{{\\alpha},(t , f)} \\sqrt{\\frac{MSE}{n}} $</strong></p>\n",
    "\n",
    "The value of $q_{{\\alpha},(t , f)}$ is obtained from the tukey table.<br>\n",
    "Where,<br>\n",
    "t: Number of treatments<br>\n",
    "f: degrees of freedom for error ($df_{e}$)<br>\n",
    "MSE: Mean error sum of squares (= $\\frac{ESS}{df_{e}}$ = $\\sum_{i}^{t}\\sum_{j}^{n_{i}}{(x_{ij} - \\bar{x_{i}}.)}^{2}$)<br>\n",
    "n: Number of observations in a treatment\n",
    "\n",
    "This test is efficient when the sample size for each treatment is equal. If the sample size is not equal fo each treatment then we can use the `Scheffe test`. The `scikit_posthocs.posthoc_scheffe()` can be used to perform the test."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e706e3",
   "metadata": {},
   "source": [
    "### Example:\n",
    "\n",
    "#### 1. Ryan is a production manager at an industry manufacturing alloy seals. They have 4 machines - A, B, C and D. Ryan wants to study whether all the machines have equal efficiency. Ryan collects data of tensile strength from all the 4 machines as given. Perform the post-hoc test to find out which machine has a different average. Test at 5% level of significance.\n",
    "\n",
    "<img src='1_ANOVA.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b916f477",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Multiple Comparison of Means - Tukey HSD, FWER=0.05</caption>\n",
       "<tr>\n",
       "   <th>group1</th>    <th>group2</th>   <th>meandiff</th>  <th>p-adj</th>   <th>lower</th>    <th>upper</th>  <th>reject</th>\n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Machine_A</td> <td>Machine_B</td>   <td>-11.1</td>  <td>0.0044</td> <td>-18.8842</td>  <td>-3.3158</td>  <td>True</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Machine_A</td> <td>Machine_C</td>  <td>-18.74</td>   <td>0.001</td> <td>-26.5242</td> <td>-10.9558</td>  <td>True</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Machine_A</td> <td>Machine_D</td>   <td>5.46</td>   <td>0.2265</td>  <td>-2.3242</td>  <td>13.2442</td>  <td>False</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Machine_B</td> <td>Machine_C</td>   <td>-7.64</td>  <td>0.0553</td> <td>-15.4242</td>  <td>0.1442</td>   <td>False</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Machine_B</td> <td>Machine_D</td>   <td>16.56</td>   <td>0.001</td>  <td>8.7758</td>   <td>24.3442</td>  <td>True</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Machine_C</td> <td>Machine_D</td>   <td>24.2</td>    <td>0.001</td>  <td>16.4158</td>  <td>31.9842</td>  <td>True</td> \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.table.SimpleTable'>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use the same dataframe created above\n",
    "# perform tukey's range test to compare the mean efficiency for pair of machines\n",
    "# pass the tensile strength to the parameter, 'data'\n",
    "# pass the name of the machine to the parameter, 'groups'\n",
    "comp = mc.MultiComparison(data = df_machine['Strength'], \n",
    "                          groups = df_machine['Machine'])\n",
    "# tukey's range test\n",
    "post_hoc = comp.tukeyhsd()\n",
    "\n",
    "# print the summary table\n",
    "post_hoc.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd6c2ac",
   "metadata": {},
   "source": [
    "The `reject=False` for pairs (machine_A, machine_D) and (machine_B, machine_C) denotes that we fail to reject the null hypothesis; and conclude that the average tensile strength due to machine_A and machine_D, machine_B and machine_C is same.\n",
    "\n",
    "For the pairs (machine_A, machine_B), (machine_A, machine_C), (machine_B, machine_D), and (machine_C, machine_D) the average tensile strength is not the same.\n",
    "\n",
    "The values in the columns `lower` and `upper` represent the lower and upper bound of the 95% confidence interval for the mean difference. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed4aeffe",
   "metadata": {},
   "source": [
    "### Summary of Tukey HSD Test\n",
    "\n",
    "A Pairwise Tukey HSD Test is used in Anova to find the difference in the mean which is resulting in variance in the categories.In other words, this test reflects the difference in the performance amongst categories.\n",
    "\n",
    "<a id=\"non-para\"></a>\n",
    "\n",
    "## Kruskall Wallis Test\n",
    "\n",
    "* If one of the assumptions of one-way ANOVA is not satisfied, then we can perform the **Kruskal-Wallis H test which is a non-parametric equivalent test for ANOVA.**\n",
    "\n",
    "* Wilcoxon Signed-Ranks test is the nonparametric version of the Two Sample Related T-Test\n",
    "\n",
    "* If the Data is not following Normal Distribution, then one can use Mann Whitney U test inplace of Independent Two Sample T-Test. It is also known as Mann Whitney Wilcoxon Test or the Wilcoxon Rank Sum Test.\n",
    "\n",
    "A gym trainer wants to provide an energy bar to all his customers to increase muscle strength. Three different companies approached the gym trainer with their high-quality energy bars. The trainer collects an amount of calcium (in g) in the energy bar from three companies and he wants to study whether all the bars have an equal amount of calcium on average. Test at 5% level of significance.\n",
    "\n",
    "given data:\n",
    "\n",
    "   * alpha_bar = [24.4, 20.7, 56.9, 19.5]\n",
    "   * beta_bar = [53.2, 54.7, 20.5, 15.8, 56.6]\n",
    "   * gamma_bar = [54, 31, 22.8, 24.7]\n",
    "   \n",
    "* **Ho: That All the Energy Bars have Same Quantity of Calcium**\n",
    "* **Ha: That All the Energy Bars Do Not have Same Quantity of Calcium**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "13540d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# given data\n",
    "# amount of calcium in alpha_bar\n",
    "alpha = [24.4, 20.7, 56.9, 19.5]\n",
    "\n",
    "# amount of calcium in beta_bar\n",
    "beta = [53.2, 54.7, 20.5, 15.8, 56.6]\n",
    "\n",
    "# amount of calcium in gamma_bar\n",
    "gamma = [54, 31, 22.8, 24.7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0302d59d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ShapiroResult(statistic=0.7282745838165283, pvalue=0.023655038326978683)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check Normality\n",
    "stats.shapiro(alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "65685b05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LeveneResult(statistic=0.16749212708722086, pvalue=0.8481074994770258)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check Variance....\n",
    "stats.levene(alpha,beta,gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1dd3efa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KruskalResult(statistic=0.22747252747252844, pvalue=0.8924933076960211)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.kruskal(alpha,beta,gamma)   # for more than 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "93174281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fail to reject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "24819ef7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MannwhitneyuResult(statistic=5.0, pvalue=0.4857142857142857)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.mannwhitneyu(alpha,gamma)   # for 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee4880f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "STAT - Faculty Notebook (Day 3) [v2.0 - 301020].ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
